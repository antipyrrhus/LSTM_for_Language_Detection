# LSTM_for_Language_Detection

In this LSTM Neural Network experiment, I build character-sequential prediction models for differentiating amongst several different languages (e.g. English, French, Latin, Dutch, etc.) based on 5-character substrings and the conditional log likelihood of a given string for each model. I then demonstrate an improved pre-processing method for the training dataset of each language based on varying the substring lengths from 0 to 5, leading to significant performance improvement.

To run, open the .ipynb file in iPython Notebook. Uses Keras and Sklearn.
